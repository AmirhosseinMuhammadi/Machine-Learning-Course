{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924049d0-000c-4156-9d63-7958b6edaaa2",
   "metadata": {},
   "source": [
    "# Chapter 4: Non-linearity\n",
    "\n",
    "While linearity serves as the essential building block for recognizing linear patterns, non-linearity fundamentally expands what machine learning can model. It captures the complex, real-world relationships where outputs are not simply a weighted sum of inputs, such as intricate interactions, curves, and decision boundaries. By incorporating non-linear functions—like activation layers in neural networks or kernel transformations—models can learn from data where the underlying patterns are far more sophisticated than a straight line or a flat plane. Thus, non-linearity moves learning systems beyond basic linear correlations to address the true, often convoluted, nature of the data they seek to understand.\n",
    "\n",
    "**Thus, the Core Idea is Non-linear Patterns.**\n",
    "\n",
    "## Table of Contents\n",
    "- [Feedforward Neural Networks](#feedforward-neural-networks)\n",
    "- [Multi-layer Perceptron (MLP)](#multi-layer-perceptron-mlp)\n",
    "- [Activation Functions](#activation-functions)\n",
    "- [Regularization and Generalization](#regularization-and-generalization)\n",
    "- [Hyperparameter Tuning](#hyperparameter-tuning)\n",
    "- [Cross Validation](#cross-validation)\n",
    "- [Regression](#regression)\n",
    "- [Classification](#classification)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f871aa8-3d06-45a0-ac1c-115b6df0f5c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feedforward Neural Networks\n",
    "A feedforward neural network is a foundational type of artificial neural network where information flows in one direction only from the **input layer**, through a series of **hidden layers**, to the **output layer** and there are **no feedback connections**. It consists of interconnected **neurons**, each applying a **linear transformation** followed by a **non-linear activation function**, which allows the network to learn and model **complex, non-linear relationships** within data as shown in the following figure. By adjusting the weights through a training process like **backpropagation**, feedforward networks can approximate highly intricate functions, making them powerful tools for tasks like classification and regression. Despite their simplicity in structure compared to recurrent or convolutional networks, they serve as the essential building block for many deep learning architectures, forming the basis for understanding more advanced models.\n",
    "<div>\n",
    "    <img src=\"../figures/figure_4_1_non-linear_regression.png\" alt=\"Non-linear Regression\" style=\"width: 500px\">\n",
    "    <img src=\"../figures/figure_3_5_non-linear_classification.png\" alt=\"Non-linear Classification\" style=\"width: 500px\">\n",
    "</div>\n",
    "\n",
    "## Multi-layer Perceptron (MLP)\n",
    "As mentioned in the previous chapter, **logistic regression** in basically a neural network. In fact logistic regression shares deep conceptual roots with neural networks, particularly **perceptrons and multi-layer perceptrons (MLPs)**, as all apply a linear transformation to inputs before passing them through an **activation function**. MLPs build on this foundation by chaining together multiple such units with **non-linear activations** in **hidden layers**, creating a **deep architecture** capable of learning **hierarchical representations** and **complex, non-linear patterns**. In essence, logistic regression is a single-layer neural network **without hidden layers**.\n",
    "\n",
    "This progression from logistic regression to deeper networks becomes crucial for tackling problems with intricate, non-linear relationships in the data, where a simple linear boundary is insufficient. While logistic regression is preferred for linearly separable data, interpretability, or smaller datasets, MLPs are the tool of choice for modeling sophisticated patterns in large-scale, complex scenarios, despite their **black box nature**.\n",
    "\n",
    "<img src=\"../figures/figure_3_10_logistic_regression_vs_mlp.png\" alt=\"Logistic Regression vs MLP\">\n",
    "\n",
    "## Activation Functions\n",
    "Activation functions are the essential non-linear components within neural network neurons that transform weighted input sums, enabling the network to learn and model complex, real-world patterns beyond simple linear relationships. Some of the most used activation functions are listed and represented below.\n",
    "\n",
    "- **Sigmoid (Logistic) Function**\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "- **Hyperbolic Functions (tanh)**\n",
    "$$ \\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} $$\n",
    "\n",
    "- **Rectified Linear Unit (ReLU)**\n",
    "$$ \\text{ReLU}(z) = \\max(0, z) $$\n",
    "\n",
    "- **Leaky ReLU**\n",
    "$$ \\text{Leaky ReLU}(z) = \\max(\\alpha z, z) \\quad \\text{where } \\alpha \\in (0, 1) $$\n",
    "\n",
    "- **Exponential Linear Unit (ELU)**\n",
    "$$ \\text{ELU}(z) = \n",
    "\\begin{cases} \n",
    "z & \\text{if } z > 0 \\\\\n",
    "\\alpha(e^{z} - 1) & \\text{if } z \\leq 0\n",
    "\\end{cases} $$\n",
    "\n",
    "- **Softmax (for multiclass problems)**\n",
    "$$ \\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{k} e^{z_j}} \\quad \\text{for } i = 1, \\dots, \\text{k (Number of classes)}$$\n",
    "\n",
    "<img src=\"../figures/figure_4_2_activation_functions.png\" alt=\"Activation Functions\">\n",
    "\n",
    "ReLU (Rectified Linear Unit) is primarily and overwhelmingly used in **hidden layers** of modern neural networks. It has become the default activation function for most hidden layers across various architectures. On the other hand, the **output layer** uses different activations (sigmoid, softmax or linear) depending on the specific prediction task. Sigmoid is employed for binary classification, softmax for multiclass classification, and linear (no activation) for regression.\n",
    "\n",
    "## Regularization and Generalization\n",
    "**Regularization** is a set of techniques used to improve **generalization** which is the ability of a model to perform well on unseen (test) data. These techniques prevent **underfitting/overfitting** and make the model more **robust** in the presence of **uncertainties**.\n",
    "\n",
    "Models can suffer from underfitting (high bias), where they are too simple to capture patterns in the training data, leading to **low accuracy on both the training and test data**. Alternatively, models may overfit (high variance), where they **memorize** training examples, achieving **high training accuracy** but failing to generalize, which is reflected in a significant **drop in accuracy on the test data**.\n",
    "\n",
    "<img src=\"../figures/figure_4_3_generalization.png\" alt=\"Generalization\">\n",
    "\n",
    "To prevent underfitting/overfitting and encourage better generalization, there are common regularization methods shown in the following figure such as **parameter penalties** (e.g., L1/L2 and elastic-net regularization in linear models), **early stopping**, **dropout** in neural networks and **data augmentation** for vision and language tasks. These techniques introduce constraints or noise during training, forcing the model to learn robust and transferable representations.\n",
    "\n",
    "<img src=\"../figures/figure_4_4_regularization_techniques.png\" alt=\"Regularization Techniques\">\n",
    "\n",
    "## Hyperparameter Tuning\n",
    "Hyperparameters are the **configuration settings** for machine learning models that must be set **before training** and are not learned from the data. Hyperparameter **tuning** is the systematic process of searching for the **optimal combination** of these settings to maximize a model's performance on a given task. Some of the basic and primary hyperparameters for MLP are shown in the following figure.\n",
    "\n",
    "<img src=\"../figures/figure_4_5_hyperparameters.png\" alt=\"Hyperparameters\">\n",
    "\n",
    "There are different hyperparameter tuning methods to find optimal hyperparameter values by searching through hyperparameter space. Some of them are listed in the following.\n",
    "\n",
    "- **Grid Search** exhaustively tests all possible combinations from a predefined hyperparameter grid, guaranteeing the best combination within the grid but becoming computationally expensive as parameters increase.\n",
    "- **Random Search** randomly samples hyperparameter combinations from specified distributions for a set number of iterations, often finding good solutions faster than Grid Search with similar performance.\n",
    "- **Bayesian Optimization** uses past evaluation results to build a probabilistic model of the objective function, intelligently selecting the most promising hyperparameters to test next for efficient optimization.\n",
    "\n",
    "## Cross Validation\n",
    "Cross-validation is a fundamental model **evaluation technique** in machine learning that assesses how well a model will generalize to unseen data by systematically splitting the dataset into **multiple training and validation** folds. Instead of using a single train-test split, it rotates which portion of data serves as validation such as in 5-fold cross-validation where the data is divided into 5 parts, each part used once as a validation set while the model trains on the remaining 4. This process provides a **more reliable and stable** performance estimate, helps detect overfitting by showing variance across folds, and is particularly valuable for model selection and hyperparameter tuning when combined with methods like GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b2904-7031-4016-a9c1-44571c0933e7",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8874c1ff-01db-4074-93c5-c9234c31631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "housing_data = fetch_california_housing()\n",
    "X, y = housing_data.data, housing_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc3c3b-46a5-4e69-861d-11ab23f56718",
   "metadata": {},
   "source": [
    "### Using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d25ab469-a5dd-4176-b6cb-83cfdfdf56d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.43469869\n",
      "Validation score: 0.685305\n",
      "Iteration 2, loss = 0.20022335\n",
      "Validation score: 0.719098\n",
      "Iteration 3, loss = 0.18551986\n",
      "Validation score: 0.724223\n",
      "Iteration 4, loss = 0.17624409\n",
      "Validation score: 0.707885\n",
      "Iteration 5, loss = 0.17103419\n",
      "Validation score: 0.708339\n",
      "Iteration 6, loss = 0.16789561\n",
      "Validation score: 0.742359\n",
      "Iteration 7, loss = 0.16246772\n",
      "Validation score: 0.753059\n",
      "Iteration 8, loss = 0.15773143\n",
      "Validation score: 0.725224\n",
      "Iteration 9, loss = 0.15582111\n",
      "Validation score: 0.757584\n",
      "Iteration 10, loss = 0.15325163\n",
      "Validation score: 0.762639\n",
      "Iteration 11, loss = 0.15120797\n",
      "Validation score: 0.753089\n",
      "Iteration 12, loss = 0.14898966\n",
      "Validation score: 0.769142\n",
      "Iteration 13, loss = 0.14633009\n",
      "Validation score: 0.767420\n",
      "Iteration 14, loss = 0.14432939\n",
      "Validation score: 0.763155\n",
      "Iteration 15, loss = 0.14347782\n",
      "Validation score: 0.759446\n",
      "Iteration 16, loss = 0.14409322\n",
      "Validation score: 0.765161\n",
      "Iteration 17, loss = 0.14600889\n",
      "Validation score: 0.769084\n",
      "Iteration 18, loss = 0.14341292\n",
      "Validation score: 0.772756\n",
      "Iteration 19, loss = 0.13936104\n",
      "Validation score: 0.768998\n",
      "Iteration 20, loss = 0.13796712\n",
      "Validation score: 0.771202\n",
      "Iteration 21, loss = 0.13740834\n",
      "Validation score: 0.778645\n",
      "Iteration 22, loss = 0.13631762\n",
      "Validation score: 0.775258\n",
      "Iteration 23, loss = 0.13540951\n",
      "Validation score: 0.779633\n",
      "Iteration 24, loss = 0.13581657\n",
      "Validation score: 0.776793\n",
      "Iteration 25, loss = 0.13419979\n",
      "Validation score: 0.773213\n",
      "Iteration 26, loss = 0.13935390\n",
      "Validation score: 0.770876\n",
      "Iteration 27, loss = 0.13327206\n",
      "Validation score: 0.783494\n",
      "Iteration 28, loss = 0.13314654\n",
      "Validation score: 0.781798\n",
      "Iteration 29, loss = 0.13206231\n",
      "Validation score: 0.779277\n",
      "Iteration 30, loss = 0.13155646\n",
      "Validation score: 0.779861\n",
      "Iteration 31, loss = 0.13131127\n",
      "Validation score: 0.780032\n",
      "Iteration 32, loss = 0.13123798\n",
      "Validation score: 0.777495\n",
      "Iteration 33, loss = 0.13037580\n",
      "Validation score: 0.763714\n",
      "Iteration 34, loss = 0.12913305\n",
      "Validation score: 0.784742\n",
      "Iteration 35, loss = 0.12894540\n",
      "Validation score: 0.779047\n",
      "Iteration 36, loss = 0.12930912\n",
      "Validation score: 0.782082\n",
      "Iteration 37, loss = 0.12833724\n",
      "Validation score: 0.781964\n",
      "Iteration 38, loss = 0.12837988\n",
      "Validation score: 0.785384\n",
      "Iteration 39, loss = 0.12765084\n",
      "Validation score: 0.786729\n",
      "Iteration 40, loss = 0.13445775\n",
      "Validation score: 0.776612\n",
      "Iteration 41, loss = 0.12786248\n",
      "Validation score: 0.784800\n",
      "Iteration 42, loss = 0.12679882\n",
      "Validation score: 0.784858\n",
      "Iteration 43, loss = 0.12717524\n",
      "Validation score: 0.786443\n",
      "Iteration 44, loss = 0.12764421\n",
      "Validation score: 0.784482\n",
      "Iteration 45, loss = 0.12587728\n",
      "Validation score: 0.790309\n",
      "Iteration 46, loss = 0.12673229\n",
      "Validation score: 0.787951\n",
      "Iteration 47, loss = 0.12549889\n",
      "Validation score: 0.788767\n",
      "Iteration 48, loss = 0.12436833\n",
      "Validation score: 0.788420\n",
      "Iteration 49, loss = 0.12438969\n",
      "Validation score: 0.775213\n",
      "Iteration 50, loss = 0.12523515\n",
      "Validation score: 0.794382\n",
      "Iteration 51, loss = 0.12514741\n",
      "Validation score: 0.790970\n",
      "Iteration 52, loss = 0.12529406\n",
      "Validation score: 0.787126\n",
      "Iteration 53, loss = 0.12410788\n",
      "Validation score: 0.783482\n",
      "Iteration 54, loss = 0.12368008\n",
      "Validation score: 0.789215\n",
      "Iteration 55, loss = 0.12375995\n",
      "Validation score: 0.788138\n",
      "Iteration 56, loss = 0.12289456\n",
      "Validation score: 0.785273\n",
      "Iteration 57, loss = 0.12290096\n",
      "Validation score: 0.793374\n",
      "Iteration 58, loss = 0.12373725\n",
      "Validation score: 0.778661\n",
      "Iteration 59, loss = 0.12414621\n",
      "Validation score: 0.791903\n",
      "Iteration 60, loss = 0.12258887\n",
      "Validation score: 0.788943\n",
      "Iteration 61, loss = 0.12216467\n",
      "Validation score: 0.787745\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MSE: 0.2720\n",
      "R²: 0.7925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Train MLP\n",
    "mlp_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 32),      # Two hidden layers: 64 and 32 neurons\n",
    "    activation='relu',                # ReLU activation\n",
    "    solver='adam',                    # Adam optimizer\n",
    "    alpha=0.0001,                     # L2 regularization strength\n",
    "    learning_rate='adaptive',         # Adaptive learning rate\n",
    "    learning_rate_init=0.001,         # Initial learning rate\n",
    "    max_iter=500,                     # Maximum epochs\n",
    "    batch_size=32,                    # Mini-batch size\n",
    "    random_state=42,\n",
    "    verbose=True,                     # Enable verbose output to see training progress\n",
    "    early_stopping=True,              # Stop if no improvement\n",
    "    validation_fraction=0.1,          # 10% of training for validation\n",
    "    n_iter_no_change=10               # Stop after 10 epochs without improvement\n",
    ")\n",
    "mlp_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = mlp_regressor.predict(X_test_scaled)\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b2dbb9-521f-46e9-8a90-f38ee336de77",
   "metadata": {},
   "source": [
    "### Using Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e66da3-008a-45a7-88c5-9cbaec21cf19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efd001d5-b248-40be-8ffa-1247b9eb9347",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81c957d0-5fc4-4858-a868-d693694e44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the dataset\n",
    "iris_dataset = load_iris()\n",
    "\n",
    "X = iris_dataset['data']\n",
    "y = iris_dataset['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9845988-e9a7-45a0-ae25-2b6573705a73",
   "metadata": {},
   "source": [
    "### Using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6682e1a4-bc56-4c4c-bb8d-aafaf62a666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.11465375\n",
      "Validation score: 0.583333\n",
      "Iteration 2, loss = 1.01962305\n",
      "Validation score: 0.666667\n",
      "Iteration 3, loss = 0.94226636\n",
      "Validation score: 0.666667\n",
      "Iteration 4, loss = 0.87534482\n",
      "Validation score: 0.666667\n",
      "Iteration 5, loss = 0.81706405\n",
      "Validation score: 0.666667\n",
      "Iteration 6, loss = 0.76520880\n",
      "Validation score: 0.666667\n",
      "Iteration 7, loss = 0.71489135\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.66770266\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.62657772\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.58816467\n",
      "Validation score: 0.750000\n",
      "Iteration 11, loss = 0.55373118\n",
      "Validation score: 0.666667\n",
      "Iteration 12, loss = 0.52055804\n",
      "Validation score: 0.750000\n",
      "Iteration 13, loss = 0.49217496\n",
      "Validation score: 0.750000\n",
      "Iteration 14, loss = 0.46558355\n",
      "Validation score: 0.750000\n",
      "Iteration 15, loss = 0.44178697\n",
      "Validation score: 0.750000\n",
      "Iteration 16, loss = 0.42021906\n",
      "Validation score: 0.750000\n",
      "Iteration 17, loss = 0.40019149\n",
      "Validation score: 0.750000\n",
      "Iteration 18, loss = 0.38087926\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Performance:\n",
      "Accuracy: 0.8333\n",
      "Precision: 0.8929\n",
      "Recall: 0.8333\n",
      "F1-Score: 0.8269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Train MLP\n",
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),      # Two hidden layers: 64 and 32 neurons\n",
    "    activation='relu',                # ReLU activation\n",
    "    solver='adam',                    # Adam optimizer\n",
    "    alpha=0.0001,                     # L2 regularization strength\n",
    "    learning_rate='adaptive',         # Adaptive learning rate\n",
    "    learning_rate_init=0.001,         # Initial learning rate\n",
    "    max_iter=500,                     # Maximum epochs\n",
    "    batch_size=32,                    # Mini-batch size\n",
    "    random_state=42,\n",
    "    verbose=True,                     # Enable verbose output to see training progress\n",
    "    early_stopping=True,              # Stop if no improvement\n",
    "    validation_fraction=0.1,          # 10% of training for validation\n",
    "    n_iter_no_change=10               # Stop after 10 epochs without improvement\n",
    ")\n",
    "mlp_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = mlp_classifier.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1, 2])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"MLP Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4723a-01f5-427f-a5e5-f152ddbd8d55",
   "metadata": {},
   "source": [
    "### Using Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798981f-6186-481f-9af2-68a02c9f65c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c69b74b-58dd-482f-9f2b-2e7a495b6f87",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] \"User Guide, Scikit-Learn Documentation\", https://scikit-learn.org/stable/user_guide.html, Accessed October 2025.\n",
    "\n",
    "[2] Goodfellow, Ian., Bengio, Yoshua., Courville, Aaron., \"Deep Learning\", MIT Press, 2016.\n",
    "\n",
    "[3] Grus, Joel., \"Data Science from Scratch\", O'Reilly, 2015.\n",
    "\n",
    "[4] Geiger, Andreas. \"Deep Learning\", Lecture, University of Tübingen, https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/lectures/deep-learning/, Accessed November 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac2ec1-5a06-425b-b33c-c226ed4c4cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
